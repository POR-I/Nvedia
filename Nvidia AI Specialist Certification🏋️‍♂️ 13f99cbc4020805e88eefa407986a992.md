# Nvidia AI Specialist CertificationğŸ‹ï¸â€â™‚ï¸

# í”„ë¡œì íŠ¸ ê°œìš”(**Overview of the Project)**

- **ë°°ê²½ ì •ë³´ ì†Œê°œ(Backgrounds of project)**
- **í”„ë¡œì íŠ¸ì˜ ì „ë°˜ì  ë‚´ìš©(General description of the current project)**
- **ì œì•ˆí•˜ëŠ” í”„ë¡œì íŠ¸ì˜ ê°•ì 
(Proposed idea for enhancements to the project)**
- **í”„ë¡œì íŠ¸ì˜ ê°€ì¹˜(Value and significance of this project)**
- **ì§ë©´í•˜ê³  ìˆëŠ” í•œê³„(Current limitations)**
- **ê²°ê³¼ë¬¼(Results)**

# **ğŸ‹ï¸â€â™‚ï¸**  í”„ë¡œì íŠ¸ ì£¼ì œ (Title) **ğŸ‹ï¸â€â™‚ï¸**

## **YOLOV5ë¥¼ ì´ìš©í•œ í”¼íŠ¸ë‹ˆìŠ¤ ì†Œë„êµ¬ íŒë³„**

---

## **Fitness Equipment Identification Using YOLOV5**

# ë°°ê²½ ì •ë³´

   **Background information**

---

<aside>
**ì´ í”„ë¡œì íŠ¸ë¥¼ í†µí•´ ê³ ê°ì€ í”¼íŠ¸ë‹ˆìŠ¤ ì†Œí’ˆì˜ ì •í™•í•œ ì´ë¦„ê³¼ ìš©ë„ë¥¼ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤**

**ì‚¬ë¬¼ì„ ë‹¤ë¥´ê²Œ ì¸ì‹í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” YOLOv5 ê¸°ë°˜ ì‚¬ë¬¼ ì¸ì‹ ëª¨ë¸**

**ì†Œí’ˆì„ ì‚¬ìš©í•˜ì—¬ ì‹¤ì‹œê°„ìœ¼ë¡œ ì†Œí’ˆì„ ì¸ì‹í•˜ê³  ì†Œí’ˆì˜ ì´ë¦„ì„ ì•Œë ¤ì£¼ëŠ” ì‹œìŠ¤í…œ**

**ê±´ì¶•ì— ê´€í•œ ê²ƒì…ë‹ˆë‹¤. ê³ ê°ì€ ì¹´ë©”ë¼ ì•ì— ë‹¤ì–‘í•œ ì†Œí’ˆì„ ê°€ì ¸ì˜µë‹ˆë‹¤**

**ëŒ€ë©´í•˜ì—¬ ì‹œìŠ¤í…œì´ ì´ë¥¼ ì¸ì‹í•˜ê³  ë„êµ¬ì˜ ì´ë¦„ê³¼ ìš©ë„ë¥¼ ì¦‰ì‹œ ì•Œë ¤ì¤ë‹ˆë‹¤**

**ìš´ë™ ë„êµ¬ì™€ ìš´ë™ íš¨ê³¼ì— ëŒ€í•´ ìì„¸íˆ ì•Œì•„ë³´ê¸° ìœ„í•´ ê³ ê°ì—ê²Œ ì œê³µí•©ë‹ˆë‹¤**

**ë¹„ìœ¨ì„ ë†’ì´ê³  ì˜¬ë°”ë¥¸ ë„êµ¬ ì‚¬ìš© ë°©ë²•ì„ ë°°ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.**

</aside>

---

This project aims to build a system that uses a YOLOv5-based object recognition model to identify fitness accessories in real-time and provide their names, helping customers quickly recognize the correct names and purposes of these items. When customers present various accessories in front of the camera, the system recognizes them and immediately provides the name and purpose of each tool. Through this, customers can learn more about exercise equipment, increase their workout efficiency, and learn the correct ways to use the tools.

---

# í”„ë¡œì íŠ¸ì˜ ì „ë°˜ì  ì„¤ëª…

  **General description of the current project**

---

<aside>
ğŸ‹ï¸ **ìš´ë™ ì¤‘ì—ëŠ” ë‹¤ì–‘í•œ ì†Œë„êµ¬ë“¤ì´ ì‚¬ìš©ë˜ì§€ë§Œ, ë§ì€ ê³ ê°ë“¤ì´ ì´ ì†Œë„êµ¬ë“¤ì˜ ì´ë¦„ì„ ì •í™•íˆ ì¸ì‹í•˜ì§€ ëª»í•˜ëŠ” ê²½ìš°ê°€ ë§ë‹¤. ì¼€í‹€ë²¨, ìš”ê°€ ë¸”ë¡, ë¼í¬ë¡œìŠ¤ ë³¼, í¼ ë¡¤ëŸ¬ ë“± ê°ê¸° ë‹¤ë¥¸ ì†Œë„êµ¬ë“¤ì€ ê°ê°ì˜ ìš´ë™ì— ë§ëŠ” ì¤‘ìš”í•œ ì—­í• ì„ í•œë‹¤. í•˜ì§€ë§Œ ì´ ë„êµ¬ë“¤ì˜ ì •í™•í•œ ëª…ì¹­ì„ ëª¨ë¥´ê±°ë‚˜ í˜¼ë™í•˜ëŠ” ê²½ìš°ê°€ ìì£¼ ë°œìƒí•œë‹¤. ì´ë¡œ ì¸í•´ ê³ ê°ë“¤ì€ ìš´ë™ ì¤‘ì— ì–´ë–¤ ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì•¼ í•˜ëŠ”ì§€, ì–´ë–»ê²Œ í™œìš©í•´ì•¼ í•˜ëŠ” ì§€ì— ëŒ€í•œ í˜¼ë€ì„ ê²ªê³  ìˆë‹¤. ë˜í•œ, ì´ë¦„ì„ ëª°ë¼ ì œëŒ€ë¡œ ëœ ì •ë³´ë¥¼ ì°¾ê¸° ìœ„í•´ ì¶”ê°€ì ì¸ ê²€ìƒ‰ì„ í•´ì•¼ í•˜ê±°ë‚˜, ì˜¬ë°”ë¥¸ ë„êµ¬ë¥¼ ì„ íƒí•˜ëŠ” ë° ì‹œê°„ì´ ë‚­ë¹„ë˜ê³¤ í•˜ê¸°ì— ì´ë¥¼ ë°©ì§€í•˜ì—¬ ì†Œë„êµ¬ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¸ì‹í•˜ê³  íŠ¸ë ˆì´ë‹ì— ì‹¤ìš©ì ì¸ ì •ë³´ë¥¼ ì œê³µí•œë‹¤.**

</aside>

---

Various accessories are used during exercise, but many customers often fail to accurately recognize the names of these accessories. Different tools such as kettlebells, yoga blocks, lacrosse balls, and foam rollers each play important roles in specific exercises. However, people frequently don't know or confuse the exact names of these tools. As a result, customers experience confusion about which tools to use during workouts and how to utilize them. Additionally, not knowing the names often leads to the need for additional searches to find proper information or wasted time in selecting the right tool. To prevent this, we provide real-time recognition of accessories and practical training information.

# ì œì•ˆí•˜ê³  ì‹¶ì€ í”„ë¡œì íŠ¸ì˜ ê°•ì 

 **Proposed idea for enhancements to the project**     

---

---

- **íš¨ìœ¨ì ì¸ í•™ìŠµ:** 
ê³ ê°ë“¤ì€ ì§ì ‘ ê²€ìƒ‰í•˜ì§€ ì•Šê³ ë„ ì‹¤ì‹œê°„ìœ¼ë¡œ ë„êµ¬ì— ëŒ€í•œ ì •ë³´ë¥¼ ì–»ì„ ìˆ˜ ìˆì–´ í•™ìŠµ ì†ë„ ì¦ê°€
- **ì‚¬ìš©ì ê²½í—˜ í–¥ìƒ:** 
ìš´ë™ ì¤‘ ì‚¬ìš©ë˜ëŠ” ë„êµ¬ë¥¼ ë°”ë¡œ ì¸ì‹í•  ìˆ˜ ìˆì–´ ë” ì´ìƒ í˜¼ë™ ì—†ì´ ìš´ë™ì— ì§‘ì¤‘í•˜ëŠ” í™˜ê²½ ì œê³µ
- **ìš´ë™ íš¨ê³¼ ê·¹ëŒ€í™”:** 
ì˜¬ë°”ë¥¸ ë„êµ¬ë¥¼ ì •í™•í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆì–´, ìš´ë™ íš¨ê³¼ë¥¼ ê·¹ëŒ€í™”í•˜ê³  ë¶€ìƒ ìœ„í—˜ ê°ì†Œ
- **ê¸°ìˆ ê³¼ ìš´ë™ì˜ ìœµí•©:** 
ìµœì‹  AI ê¸°ìˆ ì„ í™œìš©í•˜ì—¬ ìš´ë™ê³¼ í•™ìŠµì„ ë™ì‹œì— í•  ìˆ˜ ìˆëŠ” í™˜ê²½ì„ ì œê³µí•¨ìœ¼ë¡œì¨, ë³´ë‹¤ ìŠ¤ë§ˆíŠ¸í•œ ìš´ë™ ê²½í—˜ ì œê³µ
    
    ì‹¤ì œë¡œ PTìƒµê³¼ ê°™ì€ ê³³ì€ ë³´ì—¬ì§€ëŠ” ê²ƒê³¼ ì„œë¹„ìŠ¤ì œê³µì´ ì¤‘ìš”í•˜ê¸°ì— ì¶©ë¶„í•œ ê²½ìŸë ¥ê³¼ í¸ë¦¬í•¨ ì œê³µ(**In fact, places like PT shops offer enough competitiveness and convenience for what they see and what they serve to be important)**
    
- **íŠ¸ë ˆì´ë„ˆì™€ ê³ ê° ê°„ì˜ ì†Œí†µ ê°•í™”:** 
íŠ¸ë ˆì´ë„ˆëŠ” ê³ ê°ë“¤ì´ ë„êµ¬ë¥¼ ì˜¬ë°”ë¥´ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì¤„ ìˆ˜ ìˆìœ¼ë©°, ì´ ì‹œìŠ¤í…œì„ í†µí•´ ê³ ê°ê³¼ ì›í™œí•œ ì†Œí†µ í†µí•œ ë” ë‚˜ì€ í”¼ë“œë°± ì œê³µ

---

- **Efficient learning: Customers can obtain real-time information about tools without direct searching, increasing the speed of learning**
- **Enhanced user experience: Providing an environment where users can focus on exercising without confusion by instantly recognizing tools used during workouts**
- **Maximizing exercise effectiveness: Ability to use the correct tools accurately, maximizing exercise effects and reducing the risk of injury**
- **Integration of technology and exercise: Providing a smarter exercise experience by offering an environment where users can exercise and learn simultaneously using the latest AI technologyIn fact, places like PT shops provide sufficient competitiveness and convenience as the visual aspect and service provision are important**
- **Strengthening communication between trainers and clients: Trainers can help clients use tools correctly, and through this system, provide better feedback through smooth communication with clients**

---

# í”„ë¡œì íŠ¸ì˜ ê°€ì¹˜ì™€ ì¤‘ìš”ì„±

 **Value and significance of the project**

<aside>
ğŸ‹ï¸ **ì´ í”„ë¡œì íŠ¸ëŠ” í”¼íŠ¸ë‹ˆìŠ¤ ì†Œë„êµ¬ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¸ì‹í•˜ê³  ê·¸ ì´ë¦„ê³¼ ì‚¬ìš©ë²•ì„ ì•Œë ¤ì£¼ëŠ” AI ì‹œìŠ¤í…œìœ¼ë¡œ ë§ì€ ê³ ê°ë“¤ì´ ìš´ë™ ë„êµ¬ì˜ ì´ë¦„ì´ë‚˜ ì‚¬ìš©ë²•ì„ ì˜ ëª°ë¼ ë¹„íš¨ìœ¨ì ìœ¼ë¡œ í•™ìŠµí•˜ê±°ë‚˜ ë¶€ìƒì„ ì´ˆë˜í•  ìˆ˜ ìˆë‹¤.

ì´ ì‹œìŠ¤í…œì€ ì´ë¥¼ í•´ê²°í•˜ê³ , ê³ ê°ì´ ë„êµ¬ë¥¼ ë¹ ë¥´ê³  ì •í™•í•˜ê²Œ ì¸ì‹í•´ ìš´ë™ íš¨ê³¼ë¥¼ ê·¹ëŒ€í™”í•˜ê³  ë¶€ìƒì„ ë°©ì§€í•˜ë„ë¡ ë„ìš°ë©° YOLOv5ë¥¼ í™œìš©í•´ ë„êµ¬ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¸ì‹í•˜ê³ , íŠ¸ë ˆì´ë„ˆì™€ ê³ ê° ê°„ ì†Œí†µì„ ì›í™œí•˜ê²Œ ë§Œë“¤ì–´ ë” ì•ˆì „í•˜ê³  íš¨ìœ¨ì ì¸ ìš´ë™ í™˜ê²½ì„ ì œê³µí•œë‹¤.**

</aside>

---

**This project is an AI system that recognizes fitness accessories in real-time and provides their names and usage instructions. Many customers may learn inefficiently or risk injury due to lack of knowledge about the names or proper use of exercise equipment.**

**This system aims to solve this issue by helping customers quickly and accurately recognize tools, maximizing exercise effectiveness and preventing injuries. By utilizing YOLOv5 to recognize tools in real-time, it facilitates smoother communication between trainers and customers, providing a safer and more efficient exercise environment.**

# í•œê³„ì 

**Current limitations**

---

<aside>
ğŸ‹ï¸ **ì´ ì‹œìŠ¤í…œì€ í”¼íŠ¸ë‹ˆìŠ¤ ì†Œë„êµ¬ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¸ì‹í•˜ì—¬ ê°œì¸ ë§ì¶¤í˜• ìš´ë™ íŠ¸ë˜í‚¹ ì •ë³´ë¥¼ ì œê³µí•˜ì§€ë§Œ, ëª¨ë“  ìš´ë™ì„ ì™„ë²½í•˜ê²Œ ê°œì¸í™”í•˜ëŠ” ë°ì—ëŠ” í•œê³„ê°€ ì¡´ì¬í•œë‹¤. ì†Œë„êµ¬ì˜ ë¸Œëœë“œë‚˜ ì œì¡°ì‚¬ì— ë”°ë¼ ë””ìì¸, ìƒ‰ìƒ, í¬ê¸° ë“±ì´ ë‹¤ì–‘í•˜ê¸° ë•Œë¬¸ì— ë™ì¼í•œ ë„êµ¬ë¼ë„ ì¸ì‹ì´ ì–´ë ¤ìš´ ê²½ìš°ê°€ ë°œìƒí•  ìˆ˜ ìˆë‹¤. ì´ëŠ” ë‹¤ì–‘í•œ ì†Œë„êµ¬ì˜ ë³€í˜•ëœ í˜•íƒœë‚˜ ìƒ‰ìƒ ì°¨ì´ì— ì˜í•´ ì™„ë²½í•œ ì¸ì‹ì´ í˜ë“¤ë‹¤ëŠ” í˜„ì‹¤ì ì¸ ë„ì „ ê³¼ì œì´ì§€ë§Œ.ì§€ì†ì ì¸ ê°œì„ ì„ í†µí•´ ì ì°¨ ë” ë†’ì€ ì¸ì‹ë¥ ì„ ëª©í‘œë¡œ í•˜ê³  ìˆë‹¤.**

</aside>

---

**This system provides real-time recognition of fitness accessories and personalized exercise tracking information, but there are limitations in perfectly personalizing all exercises. Due to the variety in design, color, and size depending on the brand or manufacturer of accessories, there may be cases where even identical tools are difficult to recognize. This presents a realistic challenge in achieving perfect recognition due to the varied forms and color differences of diverse accessories. However, we aim for gradually higher recognition rates through continuous improvements.**

# ë¬¸í—Œ ê³ ì°°

 **Literature review**

---

<aside>
ğŸ‹ï¸ 1.ë¼ì´ë‹¤ì™€ ì¹´ë©”ë¼ì˜ í•œê³„ì™€ Yolov5ë¥¼ í™œìš©í•œ ê°ì²´ ê°ì§€ ë° ì¶”ì  ê¸°ìˆ ì— ëŒ€í•œ ì„ í–‰ ì—°êµ¬ë¥¼ í†µí•´ ì´ í”„ë¡œì íŠ¸ì˜ ê¸°ìˆ ì  ë°°ê²½ì„ ì¶©ë¶„í•œ íŒŒì•…ì´ í•„ìš”í•˜ë‹¤.
2.ê¼¬ê¹”ì½˜ì— ëŒ€í•œ ë‹¤ì–‘í•œ í•™ìŠµ ë°ì´í„°ì™€ ì¸ê³µì§€ëŠ¥ í•™ìŠµ: ì´ë¯¸ì§€ ì¸ì‹ , ê°ì²´ íƒì§€ ë° ë¶„ë¥˜ì— ëŒ€í•œ ë‹¤ì–‘í•œ ì´í•´ê°€ í•„ìš”í•˜ë‹¤.

</aside>

---

- **It is essential to gain a thorough understanding of the limitations of LiDAR and cameras, as well as the technical background of object detection and tracking using YOLOv5 through prior research, to adequately grasp the technological context of this project.**
- **Diverse training data for traffic signals and artificial intelligence training: A comprehensive understanding of image recognition, object detection, and classification is necessary for this project.**

# ì˜ìƒ ì·¨ë“ ë°©ë²•**(Image Acquisition Method)**:

---

- **ì¸ê³µì§€ëŠ¥ ì˜ìƒ ì·¨ë“ : ì§ì ‘ ì¼í•˜ëŠ” ê³³ì—ì„œ ê°ì¢… ì†Œë„êµ¬ë“¤ì„ ì´¬ì˜**
(Filmed various props at the place where I work)

[https://drive.google.com/file/d/12TG2KZcvgloyKzglvqSZP8Uu5N6jdAa2/view?usp=drive_link](https://drive.google.com/file/d/12TG2KZcvgloyKzglvqSZP8Uu5N6jdAa2/view?usp=drive_link)

**í•´ë‹¹ ì˜ìƒì„ ì´ìš©í•˜ì—¬ DarkLabelì—ì„œ ë¼ë²¨ë§ì„ í†µí•œ ì¶”ì¶œ**
(Use this video to extract from DarkLabel through labeling)

# **DarkLabelì„ ì´ìš©í•œ ì˜ìƒ Labeling ë° Innotation**

---

- **ë°ì´í„° ì¶”ì¶œ: ìˆ˜ì§‘í•œ ì˜ìƒì„ DarkLabelÂ ì—ì„œ ì´ë¯¸ì§€ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤.**
Extract the collected images from DarkLabel as images.
****

[DarkLabel2.4.zip](DarkLabel2.4.zip)

![Untitled](Untitled.png)

**Yolov5ëŠ” 640 * 640 ì—ì„œ ì§€ì›í•˜ë¯€ë¡œ ì›ë³¸ì˜ìƒì„ í•´ìƒë„ ë³€í™˜ í”„ë¡œê·¸ë¨ì„ 
ì´ìš©í•˜ì—¬ 640 * 640 ìœ¼ë¡œì„¤ì •í•œë‹¤.**
(Since Yolov5 is supported by 640 * 640, the original image is set to 640 * 640 using a resolution conversion program.)

![ë±ë¯¹ìŠ¤ ì¸ì½”ë”© ì„¤ì •.JPG](25d80498-33a9-49d4-acb0-a37e45c89780.png)

[[https://www.bing.com/ck/a?!&&p=17025025dbeef5d650a67a3b4a49c0218bed35529ef61e6ddbfc38d974981ab8JmltdHM9MTczMTYyODgwMA&ptn=3&ver=2&hsh=4&fclid=29425e80-95ec-62a3-2119-51b5944e63b9&psq=ë±ë¯¹ìŠ¤&u=a1aHR0cHM6Ly93d3cudmFwc2hpb24uY29tL3ZhcHNoaW9uMy9kb3dubG9hZC5waHA&ntb=1](https://www.bing.com/ck/a?!&&p=17025025dbeef5d650a67a3b4a49c0218bed35529ef61e6ddbfc38d974981ab8JmltdHM9MTczMTYyODgwMA&ptn=3&ver=2&hsh=4&fclid=29425e80-95ec-62a3-2119-51b5944e63b9&psq=%eb%b1%81%eb%af%b9%ec%8a%a4&u=a1aHR0cHM6Ly93d3cudmFwc2hpb24uY29tL3ZhcHNoaW9uMy9kb3dubG9hZC5waHA&ntb=1)](https://www.bing.com/ck/a?!&&p=17025025dbeef5d650a67a3b4a49c0218bed35529ef61e6ddbfc38d974981ab8JmltdHM9MTczMTYyODgwMA&ptn=3&ver=2&hsh=4&fclid=29425e80-95ec-62a3-2119-51b5944e63b9&psq=%eb%b1%81%eb%af%b9%ec%8a%a4&u=a1aHR0cHM6Ly93d3cudmFwc2hpb24uY29tL3ZhcHNoaW9uMy9kb3dubG9hZC5waHA&ntb=1)

[https://www.bing.com/ck/a?!&&p=17025025dbeef5d650a67a3b4a49c0218bed35529ef61e6ddbfc38d974981ab8JmltdHM9MTczMTYyODgwMA&ptn=3&ver=2&hsh=4&fclid=29425e80-95ec-62a3-2119-51b5944e63b9&psq=ë±ë¯¹ìŠ¤&u=a1aHR0cHM6Ly93d3cudmFwc2hpb24uY29tL3ZhcHNoaW9uMy9kb3dubG9hZC5waHA&ntb=1](https://www.bing.com/ck/a?!&&p=17025025dbeef5d650a67a3b4a49c0218bed35529ef61e6ddbfc38d974981ab8JmltdHM9MTczMTYyODgwMA&ptn=3&ver=2&hsh=4&fclid=29425e80-95ec-62a3-2119-51b5944e63b9&psq=%eb%b1%81%eb%af%b9%ec%8a%a4&u=a1aHR0cHM6Ly93d3cudmFwc2hpb24uY29tL3ZhcHNoaW9uMy9kb3dubG9hZC5waHA&ntb=1)

**darklabel.yaml íŒŒì¼ì„ í…ìŠ¤íŠ¸ í˜•ì‹ì´ë‚˜ VScode ì™€ ê°™ì€ ê°œë°œ í™˜ê²½ì—ì„œ ì—´ì–´
classes_setì— ë³¸ì¸ì´ ë¼ë²¨ë§ í•  ê°ì²´ ì¦‰, í´ë˜ìŠ¤ë“¤ì˜ ì´ë¦„ì„ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì¤€ë‹¤.**

(Open the darklabel.yaml file in a development environment such as text format or VScode in classes_set, the names of the objects to be labeled, that is, classes, are written in the form of a list.)

```python
classes_set: "my_classes1"   # predefined classes set (tag name of classes set)
```

```python
my_classes1:  [ "YogaBlock", "Kettlebell","MedBall","FoamRoller","LacrosseBall", "AquaBall"]
```

![í™”ë©´ ìº¡ì²˜ 2024-11-16 000257.JPG](122d2ace-03b3-48b3-9d7c-ea7f66d602b7.png)

**VS ìŠ¤íŠœë””ì˜¤ì—ì„œ ë‹¤ìŒê³¼ ê°™ì´ ì½”ë“œë¥¼ ì…ë ¥í•˜ë©´  Annotationí•  ë•Œ DarkLabel GUIì—ì„œ ì„¤ì •í•œ classesë¥¼ ë³¼ ìˆ˜ ìˆê²Œ classes_setì€ ë¯¸ë¦¬ ì„¤ì •í•´ ë†“ì€ â€˜my_classes1â€™ë¥¼ ë„£ê³  GUIì—ì„œ ë³¼ nameì„ â€™fitness_accessoriesâ€™ë¡œ ì„¤ì •í•œë‹¤**

(In order to see the classes set in the DarkLabel GUI when announcing by entering the code as follows in VS Studio, class_set adds a preset 'my_classes1' and sets the name to be viewed in the GUI to 'fitness_accessoriesâ€™)

![image.png](b7cf7ef5-a729-4acc-aead-eedcdfded97a.png)

```python
format1:    # darknet yolo (predefined format]
  fixed_filetype: 1                 # if specified as true, save setting isn't changeable in GUI
  data_fmt: [classid, ncx, ncy, nw, nh]
  gt_file_ext: "txt"                 # if not specified, default setting is used
  gt_merged: 0                    # if not specified, default setting is used
  delimiter: " "                     # if not spedified, default delimiter(',') is used
  classes_set: "my_classes1"     # if not specified, default setting is used
  name: "fitness_accessories"           # if not specified, "[fmt%d] $data_fmt" is used as default format name

```

![image.png](34721b64-c0de-4867-a483-203f7331ab20.png)

![image.png](9862f7a8-09bc-43cc-9975-e743580a2e20.png)

**ë‹¤ìŒê³¼ ê°™ì´ ê°ì²´ë¥¼ ë¼ë²¨ë§í•  ëª…ì¹­ë“¤ì´ ë‚´ê°€ ì„¤ì •í•œ í´ë˜ìŠ¤ì´ë¦„ê³¼ ê°™ì€ ê²ƒì„ GUIì—ì„œ í™•ì¸í•  ìˆ˜ ìˆë‹¤
(You can check on the GUI that the names to label objects are the same as the class names I set)**

**Open Video ë¥¼ ëˆŒëŸ¬ ë‚´ê°€ ë¼ë²¨ë§í•  ì›ë³¸ ì˜ìƒì„ ë¶ˆëŸ¬ì˜¨ë‹¤(Press Open Video to sing the original image to label)**

# ì˜ìƒì„ ì´ë¯¸ì§€ì™€ .txtíŒŒì¼ë¡œ ì¶”ì¶œí•˜ëŠ” ë°©ë²•

---

**open videoë¥¼ ì—´ì–´ ì¶”ì¶œí•  ì˜ìƒì„ ì„ íƒ í•´ì¤€ë‹¤.**

![image.png](2c470079-0ad1-468e-9a9c-24eca9a6ba05.png)

**ì˜ìƒì„ ì—´ê³  ì¶”ì¶œí•  ì´ë¯¸ì§€ë¥¼ ì €ì¥í•  í´ë”ë¥¼ ë°˜ë“œì‹œ ë§Œë“¤ê³  ë§Œë“  í´ë”ì— images í´ë”ë¥¼ ë” ë§Œë“¤ì–´ innotation ëœ .txtíŒŒì¼ê³¼ êµ¬ë³„í•´ì¤€ë‹¤.**
(Make sure you open the video and create a folder to store the image you want to extract and create more images folders in the folder you created to distinguish it from the notated .txt file.)

**Box + Label ì„ ì²´í¬í•´ì£¼ê³  ê° ì†Œë„êµ¬ì˜ ëª…ì¹­ì— ë§ê²Œ ë¼ë²¨ë§ì„ í•´ì¤ë‹ˆë‹¤
ë¼ë²¨ë§ì‹œì—ëŠ” Box + Labelì„ ì„ íƒí•˜ì—¬ ë¼ë²¨ë§ì‹œì— í™”ë©´ì„ êµ¬ë¶„í•˜ëŠ” ìš©ë„ì´ë‹¤.
(**Check the box + label and label it according to the name of each accessory
When labeling, Box + Label is selected to distinguish the screen during labeling.)

**ë¼ë²¨ë§ì„ ëª¨ë‘ ì§„í–‰í•œ í›„ ë¯¸ë¦¬ ì €ì¥í•œ í´ë” images í´ë”ì— as Images ë²„íŠ¼ì„ ëˆŒëŸ¬ ì´ë¯¸ì§€ í˜•íƒœë¡œ ì €ì¥í•´ì¤€ë‹¤.**
(After all labeling, press the as images button in the pre-saved folder images folder to save it in the form of an image.)

![image.png](9cccd937-cd2f-4979-9b57-531b8345e1f4.png)

**ì´ë¯¸ì§€ í˜•íƒœë¡œ ì €ì¥ì„ ì™„ë£Œí•œ í›„ì— save as GT ë²„íŠ¼ì„ ëˆŒëŸ¬ images í´ë”ì™€ êµ¬ë¶„ë˜ê²Œ ì €ì¥í•´ì¤€ë‹¤.ì´ëŸ° êµ¬ë¶„ ì‘ì—…ì€ ì´í›„ì— colabì— ë„£ì„ ë•Œ í›¨ì”¬ ë” í¸ë¦¬í•˜ë‹¤.**
(After you complete the save in image format, press the save as GT button to save it distinct from the images folder. This distinction is much more convenient when you put it in the colab later.)

![image.png](5ecb932d-6a33-46de-a7e8-72dc0eea9159.png)

# Colabì„ ì´ìš©í•œ Yolov5 í•™ìŠµ
(Learning Yolov5 with Colab)

---

### **1. Colabì— ì ‘ì†í•˜ì—¬ ë° êµ¬ê¸€ ë“œë¼ì´ë¸Œì™€ ì—°ê²°í•˜ì—¬ í•˜ìœ„ í´ë” ìƒì„±**
   (Connect to Colab and connect to Google Drive to create     
     subfolders)

```python
# prompt: êµ¬ê¸€ ë“œë¼ì´ë¸Œë‘ ì—°ê²°

from google.colab import drive
drive.flush_and_unmount()  # ê¸°ì¡´ ë§ˆìš´íŠ¸ í•´ì œ
drive.mount('/content/drive')  # ë‹¤ì‹œ ë§ˆìš´íŠ¸
```

```python
%cd /content/drive/MyDri
```

```python
# prompt: êµ¬ê¸€ ë“œë¼ì´ë¸Œë‘ ì—°ê²°

from google.colab import drive
drive.flush_and_unmount()  # ê¸°ì¡´ ë§ˆìš´íŠ¸ í•´ì œ
drive.mount('/content/drive')  # ë‹¤ì‹œ ë§ˆìš´íŠ¸
```

![image.png](61ecacb7-e44c-476e-9f82-a0299ed5368a.png)

---

### **2. YOLOv5 ë‹¤ìš´ë¡œë“œ
(Download YOLOv5)**

```python
##
#clone YOLOv5 and
!git clone https://github.com/ultralytics/yolov5  # clone repo
%cd yolov5
%pip install -qr requirements.txt # install dependencies
```

```python
!pip install Pillow==10.3
```

 **YOLOv5ì—ì„œ pythonì„ ì“°ëŠ”ë° Python íŒ¨í‚¤ì§€ë“¤ì„ ì‰½ê²Œ ì„¤ì¹˜, ê´€ë¦¬í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ë„êµ¬ì¸ pipì™€ ì´ë¯¸ì§€ ì²˜ë¦¬ë¥¼ ë‹´ë‹¹í•˜ëŠ” Pillowë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë‹¤ìš´ë¡œë“œ í•œë‹¤.**
(YOLOv5 downloads pip, a tool that makes it easy to install and manage Python packages, and Pillow Library, which is responsible for image processing.)
****

![image.png](e3a7d8dd-aac2-486f-a2b8-152c041cb89e.png)

---

### **3. ì´ë¯¸ì§€ íŒŒì¼ë“¤ì„ ê´€ë¦¬ í´ë” ìƒì„±**
(Create a management folder for image files)
****

```python
!mkdir -p Train/labels
!mkdir -p Train/images
!mkdir -p Val/labels
!mkdir -p Val/images
%pw
```

```python
##ê²€ì¦ ë°ì´í„° ë§Œë“¤ê¸°
import os
import shutil
from sklearn.model_selection import %pwdtrain_test_split

def create_validation_set(train_path, val_path, split_ratio=0.3):
    """
    Train ë°ì´í„°ì˜ ì¼ë¶€ë¥¼ Valë¡œ ì´ë™
    """
    # í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(os.path.join(val_path, 'images'), exist_ok=True)
    os.makedirs(os.path.join(val_path, 'labels'), exist_ok=True)

    # Train ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
    train_images = os.listdir(os.path.join(train_path, 'images'))
    train_images = [f for f in train_images if f.endswith(('.jpg', '.jpeg', '.png'))]

    # Train/Val ë¶„í• 
    _, val_images = train_test_split(train_images,
                                   test_size=split_ratio,
                                   random_state=42)

    # Valë¡œ íŒŒì¼ ë³µì‚¬
    for image_file in val_images:
        # ì´ë¯¸ì§€ ë³µì‚¬
        src_image = os.path.join(train_path, 'images', image_file)
        dst_image = os.path.join(val_path, 'images', image_file)
        shutil.copy2(src_image, dst_image)

        # ë¼ë²¨ íŒŒì¼ ë³µì‚¬
        label_file = os.path.splitext(image_file)[0] + '.txt'
        src_label = os.path.join(train_path, 'labels', label_file)
        dst_label = os.path.join(val_path, 'labels', label_file)
        if os.path.exists(src_label):
            shutil.copy2(src_label, dst_label)

    print(f"Created validation set with {len(val_images)} images")

# ì‹¤í–‰
train_path = '/content/drive/MyDrive/yolov5/Train'
val_path = '/content/drive/MyDrive/yolov5/Val'

create_validation_set(train_path, val_path)
```

**Train ë°ì´í„°ì—ì„œ ì§€ì •ëœ ë¹„ìœ¨ë§Œí¼ ì´ë¯¸ì§€ë¥¼ ì¶”ì¶œí•´ Validation ë°ì´í„°ë¡œ ë¶„ë¦¬ ë° ë³µì‚¬í•˜ê³  ì´ë¯¸ì§€ì™€ í•¨ê»˜ ë¼ë²¨ íŒŒì¼ë„ í•´ë‹¹ ê²½ë¡œë¡œ ë³µì‚¬í•˜ì—¬ Validation ë°ì´í„°ì…‹ì„ êµ¬ì„±í•œë‹¤. í•´ë‹¹ì½”ë“œì˜ ê¸°ëŠ¥ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.**
(The validation dataset is composed by extracting images from the training data at a specified rate, separating and copying them into validation data, and copying the label file along with the image to the corresponding path. The functions of the code are as follows.)
****

- **ëª¨ë¸ì˜ ì„±ëŠ¥ í‰ê°€(Evaluation of the performance of the model)**
    - Validation ë°ì´í„°ëŠ” ëª¨ë¸ì´ í•™ìŠµí•˜ì§€ ì•Šì€ ë°ì´í„°ë¡œ, ëª¨ë¸ì˜ ì¼ë°˜í™” ì„±ëŠ¥(ìƒˆë¡œìš´ ë°ì´í„°ì— ì–¼ë§ˆë‚˜ ì˜ ì‘ë™í•˜ëŠ”ì§€ë¥¼ í‰ê°€í•˜ê¸° ìœ„í•´ í•„ìš”
    (Validation data is data that the model has not learned, and is needed to evaluate the generalization performance of the model (how well it works on new data))
- **ë°ì´í„° í¸í–¥ ë°©ì§€(data bias prevention)**
    - í•™ìŠµ(Train) ë°ì´í„°ë§Œ ì‚¬ìš©í•˜ë©´ ëª¨ë¸ì´ ë°ì´í„°ì— ê³¼ì í•©(Overfitting)ë  ê°€ëŠ¥ì„±ì´ ë†’ë‹¤.
    (Using only the training data is likely to overfit the model to the data.)
    - Validation ë°ì´í„°ë¥¼ í†µí•´ ëª¨ë¸ì´ ë‹¤ì–‘í•œ ë°ì´í„°ì— ëŒ€í•´ ê· í˜• ì¡íŒ ì„±ëŠ¥ì„ ê°€ì§€ë„ë¡ í™•ì¸í•  ìˆ˜ ìˆìŒ
    (You can check the model to have balanced performance for various data)
- **í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹(Hyperparameter tuning)**
    - í•™ìŠµ ë„ì¤‘ í•™ìŠµë¥ , epoch ìˆ˜, ëª¨ë¸ êµ¬ì¡° ë“± í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•  ë•Œ Validation ë°ì´í„°ì˜ ê²°ê³¼ë¥¼ ì°¸ê³ í•˜ê³  Validation ì„±ëŠ¥ì´ ë†’ì•„ì§€ëŠ” ë°©í–¥ìœ¼ë¡œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ìµœì í™”í•œë‹¤.
    (When adjusting hyperparameters such as learning rate, number of epochs, and model structure during learning, refer to the results of validation data and optimize the hyperparameters in the direction of increasing validation performance.)
    

**Validation ë°ì´í„°ë¥¼ ë¶„ë¦¬í•˜ëŠ” ê²ƒì€ ëª¨ë¸ì˜ ì„±ëŠ¥ í‰ê°€ì™€ ê°œì„ ì„ ìœ„í•œ í•„ìˆ˜ ê³¼ì •ì´ë‹¤.**
(Isolation of validation data is an essential process for performance evaluation and improvement of the model.)

```python
def check_dataset():
    train_path = '/content/drive/MyDrive/yolov5/Train'
    val_path = '/content/drive/MyDrive/yolov5/Val'

    # Train ë°ì´í„° í™•ì¸
    train_images = len(os.listdir(os.path.join(train_path, 'images')))
    train_labels = len(os.listdir(os.path.join(train_path, 'labels')))

    # Val ë°ì´í„° í™•ì¸
    val_images = len(os.listdir(os.path.join(val_path, 'images')))
    val_labels = len(os.listdir(os.path.join(val_path, 'labels')))

    print("Dataset status:")
    print(f"Train - Images: {train_images}, Labels: {train_labels}")
    print(f"Val - Images: {val_images}, Labels: {val_labels}")

# ë°ì´í„°ì…‹ ìƒíƒœ í™•ì¸
check_dataset()
```

![ë°ì´í„°ì…‹ì˜ í¬ê¸°ê°€ ë‹¤ìŒê³¼ ê°™ì´ ëª‡ì‹­ì—ì„œ ëª‡ë°±ì¥ ì²˜ëŸ¼ í° ì°¨ì´ê°€ì—†ì„ ì •ë„ë¡œ ì°¨ì´ê°€ ë‚˜ë©´ ì´í›„ì— í•™ìŠµì‹œí‚¤ëŠ” ë° í° ë¬¸ì œê°€ ì—†ë‹¤. ì •í™•ë„ê°€ ë¯¸ë¯¸í•˜ê²Œ ë–¨ì–´ì§€ê² ì§€ë§Œ í˜„ì¬ ì›ë³¸ ì´ë¯¸ì§€ìˆ˜ì—ëŠ” ìœ ì˜ë¯¸í• ì •ë„ì˜ ì˜í–¥ì„ ë¯¸ì¹˜ì§€ ì•ŠìŒ.
(If the size of the dataset differs to the extent that there is no significant difference between a few tens and a few hundred chapters as follows, there is no big problem in learning afterwards. The accuracy will be slightly lowered, but it does not significantly affect the current number of original images.)](295dd344-e5a3-4219-adb7-5f1338aa46e0.png)

ë°ì´í„°ì…‹ì˜ í¬ê¸°ê°€ ë‹¤ìŒê³¼ ê°™ì´ ëª‡ì‹­ì—ì„œ ëª‡ë°±ì¥ ì²˜ëŸ¼ í° ì°¨ì´ê°€ì—†ì„ ì •ë„ë¡œ ì°¨ì´ê°€ ë‚˜ë©´ ì´í›„ì— í•™ìŠµì‹œí‚¤ëŠ” ë° í° ë¬¸ì œê°€ ì—†ë‹¤. ì •í™•ë„ê°€ ë¯¸ë¯¸í•˜ê²Œ ë–¨ì–´ì§€ê² ì§€ë§Œ í˜„ì¬ ì›ë³¸ ì´ë¯¸ì§€ìˆ˜ì—ëŠ” ìœ ì˜ë¯¸í• ì •ë„ì˜ ì˜í–¥ì„ ë¯¸ì¹˜ì§€ ì•ŠìŒ.
(If the size of the dataset differs to the extent that there is no significant difference between a few tens and a few hundred chapters as follows, there is no big problem in learning afterwards. The accuracy will be slightly lowered, but it does not significantly affect the current number of original images.)

---

### **4. í•™ìŠµì‹œì‘
(Start learning)**

```python
import torch
import os
from IPython.display import Image, clear_output  # to display images
```

```python
%pwd
```

**import os :  ìš´ì˜ì²´ì œì™€ ìƒí˜¸ì‘ìš©í•˜ê¸° ìœ„í•œ OS**
(OS for interacting with the operating system)

**import torch** : **ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ êµ¬ì¶•í•˜ê³  í•™ìŠµì‹œí‚¤ê¸° ìœ„í•´ ì‚¬ìš©ë˜ê³  
ë”¥ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ, ì¶”ë¡ , í…ì„œ ì—°ì‚° ë“±ì— í™œìš©ë˜ëŠ” pytorchë¼ì´ë¸ŒëŸ¬ë¦¬**

(It is used to build and train deep learning models
Pytorch library used for deep learning model training, inference, and tensor operations)

```python
import numpy as np
import tensorflow as tf
import os
from PIL import Image
from tensorflow.python.eager.context import eager_mode

def _preproc(image, output_height=512, output_width=512, resize_side=512):
    ''' imagenet-standard: aspect-preserving resize to 256px smaller-side, then central-crop to 224px'''
    with eager_mode():
        h, w = image.shape[0], image.shape[1]
        scale = tf.cond(tf.less(h, w), lambda: resize_side / h, lambda: resize_side / w)
        resized_image = tf.compat.v1.image.resize_bilinear(tf.expand_dims(image, 0), [int(h*scale), int(w*scale)])
        cropped_image = tf.compat.v1.image.resize_with_crop_or_pad(resized_image, output_height, output_width)
        return tf.squeeze(cropped_image)

def Create_npy(imagespath, imgsize, ext) :
    images_list = [img_name for img_name in os.listdir(imagespath) if
                os.path.splitext(img_name)[1].lower() == '.'+ext.lower()]
    calib_dataset = np.zeros((len(images_list), imgsize, imgsize, 3), dtype=np.float32)

    for idx, img_name in enumerate(sorted(images_list)):
        img_path = os.path.join(imagespath, img_name)
        try:
            # íŒŒì¼ í¬ê¸°ê°€ ì •ìƒì ì¸ì§€ í™•ì¸
            if os.path.getsize(img_path) == 0:
                print(f"Error: {img_path} is empty.")
                continue

            img = Image.open(img_path)
            img = img.convert("RGB")  # RGBA ì´ë¯¸ì§€ ë“± ë‹¤ë¥¸ í˜•ì‹ì´ ìˆì„ ê²½ìš° ê°•ì œë¡œ RGBë¡œ ë³€í™˜
            img_np = np.array(img)

            img_preproc = _preproc(img_np, imgsize, imgsize, imgsize)
            calib_dataset[idx,:,:,:] = img_preproc.numpy().astype(np.uint8)
            print(f"Processed image {img_path}")

        except Exception as e:
            print(f"Error processing image {img_path}: {e}")

    np.save('calib_set.npy', calib_dataset)
```

**ì´ ì½”ë“œëŠ” ì§€ì •ëœ í´ë”ì˜ ì´ë¯¸ì§€ë¥¼ ì½ì–´ë“¤ì—¬,ë¹„ìœ¨ ìœ ì§€ ë¦¬ì‚¬ì´ì¦ˆì™€ 
ì¤‘ì•™ í¬ë¡­/íŒ¨ë”©ìœ¼ë¡œ ì „ì²˜ë¦¬í•œ í›„ Numpy ë°°ì—´ë¡œ ì €ì¥í•œë‹¤.**

**ì „ì²˜ë¦¬ëœ ë°ì´í„°ëŠ”**.npy**íŒŒì¼ë¡œ ì €ì¥ë˜ì–´ ëª¨ë¸ í•™ìŠµ ë˜ëŠ” êµì • ë°ì´í„°ë¡œ í™œìš©ëœë‹¤.**

(This code reads the image of the specified folder, contains the ratio maintenance resize and Pretreatment with center crop/padding and save in a Numpy array. The preprocessed data is stored as a .npy file and used as model training or calibration data.)

```python
#ëª¨ë¸ í•™ìŠµí•˜ê¸°
!python  /content/drive/MyDrive/yolov5/train.py  --img 640 --batch 16 --epochs 300 --data /content/drive/MyDrive/yolov5/data.yaml --weights yolov5n.pt --cache --patience 0  

```

**YOLOv5ë¥¼ ì‹¤í–‰ì‹œí‚¤ê¸°ìœ„í•œ 
`train.py`ë¥¼ ì‹¤í–‰í•œë‹¤. ë‹¤ì–‘í•œ ì˜µì…˜ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ë° ë‹¤ìŒê³¼ ê°™ë‹¤.**

(YOLOv5ë¥¼ ì‹¤í–‰ì‹œí‚¤ê¸°ìœ„í•œ
train.pyë¥¼ ì‹¤í–‰í•œë‹¤. ë‹¤ì–‘í•œ ì˜µì…˜ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ë° ë‹¤ìŒê³¼ ê°™ë‹¤.)

- **`--img 640`:**
    
    **ì…ë ¥ ì´ë¯¸ì§€ì˜ í¬ê¸°ë¥¼  640x640ìœ¼ë¡œ ì„¤ì •í•œë‹¤.(**Set the size of the input image to 640x640.)
    
- **`--batch 16`:**
    
     **ë°°ì¹˜ í¬ê¸°ë¥¼ ì„¤ì •í•œë‹¤. í•œ ë²ˆì— ì²˜ë¦¬ë˜ëŠ” ì´ë¯¸ì§€ì˜ ìˆ˜ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤.
    (**Set the batch size. Indicates the number of images processed at a time.)
    
- **`--epochs 300`:**
    
     **í•™ìŠµ ë°˜ë³µ íšŸìˆ˜ ì—í­(epoch) ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
    (** Sets the total number of epochs to learn.)
    
- **`--data /content/drive/MyDrive/yolov5/data.yaml`**
    
    **ë°ì´í„°ì…‹ ë° ëª¨ë¸ êµ¬ì„±ì— ëŒ€í•œ ì„¤ì •ì´ ë‹´ê¸´ YAML íŒŒì¼ì˜ ê²½ë¡œë¥¼ ì§€ì •í•œë‹¤.**
    Specify the path to the YAML file containing settings for the dataset and model configurations.)
    
- **`--weights yolov5n.pt`:**
    
    **ë¯¸ë¦¬ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ íŒŒì¼ì˜ ê²½ë¡œë¥¼ ì§€ì •í•œë‹¤. yolov5ì—ì„œëŠ” `yolov5n.pt` íŒŒì¼ì„ ì‚¬ìš©í•˜ê³  ìˆë‹¤.
    (** Specify the path to pre-trained weight files. **`yolov5n.pt `** files are being used here.)
    
- **`--patience 0` :**
    
    **í•™ìŠµì´ ì¤‘ê°„ì— ë©ˆì¶”ëŠ”ê±¸ ë°©ì§€í•´ì¤€ë‹¤. 10ìœ¼ë¡œ ì„¤ì •í•˜ë©´ 10ë™ì•ˆ epochê°€ ë³€í™”ê°€ ì—†ìœ¼ë©´ ì •ì§€í•œë‹¤.**(It prevents learning from stopping in the middle. Set to 10, if the epoch remains unchanged for 10 years, it stops.)
    
    ---
    
    ![image.png](2367191c-4540-4cb0-91b4-5c407216b1c6.png)
    
    **í•™ìŠµì´ ì™„ë£Œë˜ë©´ yolov5/runs/train/exp10 ì˜ ê²½ë¡œì— ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆë‹¤ëŠ” ë¬¸êµ¬ë¥¼ ë³¼ ìˆ˜ ìˆë‹¤.**
    
    ---
    
    ### **5.  yolov5ëª¨ë¸ í•™ìŠµ ê²°ê³¼ ê²€ì¦**
    
    ```python
    %load_ext tensorboard
    %tensorboard --logdir /content/drive/MyDrive/yolov5/runs/train/exp10
    ```
    
    **ìœ„ì˜ ì½”ë“œë¥¼ ì´ìš©í•˜ì—¬ --logdir /content/drive/MyDrive/yolov5/runs/train/exp10ì™€ ê°™ì´ í•™ìŠµí•œ ê²½ë¡œë¥¼ë¼ë²¨ë¦¬ ì§€ì •í•˜ê³  í…ì„œë³´ë“œë¥¼ ì´ìš©í•˜ì—¬ ì‹œê°í™” í•  ìˆ˜ ìˆë‹¤.**
    

![image.png](476d1e50-27e1-47b8-939b-084be7098f62.png)

**í•™ìŠµí•œ ìë£Œë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ë¼ë²¨ë§ëœ í•´ë‹¹ ê°ì²´ê°€ ë‹¤ë¥¸ ì˜ìƒì´ë‚˜ ì´ë¯¸ì§€ì— ë‚˜ì˜¤ëŠ” ê²ƒì„ ì¬í•™ìŠµí•˜ì—¬ ê²€ì¦í•˜ëŠ” ì½”ë“œëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.** 
(The code for re-learning and verifying that the object labeled based on the learned materials appears in other images or images is as follows.)

```python
!python /content/drive/MyDrive/yolov5/detect.py --weights /content/drive/MyDrive/yolov5/runs/train/exp4/weights/best.pt --img 640 --conf 0.1 --source /content/drive/MyDrive/yolov5/Train/images
```

```python
!python /content/drive/MyDrive/yolov5/detect.py --weights /content/drive/MyDrive/yolov5/runs/train/exp5/weights/best.pt --img 640 --conf 0.1 --source /content/drive/MyDrive/yolov5/Train/ë¼ìˆ.mp4
```

# **í•™ìŠµ ê²°ê³¼ë¬¼
(The results of learning)**

**í•™ìŠµ ëŒë¦° ë¼ë²¨ ê²°ê³¼ë¬¼ train_batch**

![F1_curve.png](F1_curve.png)

![labels.jpg](labels.jpg)

![confusion_matrix.png](confusion_matrix.png)

![labels_correlogram.jpg](labels_correlogram.jpg)

![PR_curve.png](PR_curve.png)

![P_curve.png](P_curve.png)

![R_curve.png](R_curve.png)

![results.png](results.png)

![val_batch0_labels.jpg](val_batch0_labels.jpg)

![val_batch2_labels.jpg](val_batch2_labels.jpg)

![val_batch2_pred.jpg](val_batch2_pred.jpg)

![image.png](image.png)

# **í•™ìŠµê²°ê³¼ ì˜ìƒ
(Learning Results Video)**

[https://youtu.be/yWuiWQbhLDA?si=vcco28nqa3DvEiR3](https://youtu.be/yWuiWQbhLDA?si=vcco28nqa3DvEiR3)

---

[https://youtube.com/shorts/7mulq1dcq00?si=3GKYVtTEMI6OMfBT](https://youtube.com/shorts/7mulq1dcq00?si=3GKYVtTEMI6OMfBT)

---

[https://youtu.be/xB4_d9nBZXw?si=Lv8a9Qi-PQ2SNWN4](https://youtu.be/xB4_d9nBZXw?si=Lv8a9Qi-PQ2SNWN4)

---

[https://youtube.com/shorts/riOYFq0lBrA?si=aCtcZegWiGhgOptZ](https://youtube.com/shorts/riOYFq0lBrA?si=aCtcZegWiGhgOptZ)

---

[https://youtu.be/31t7jyiUw3I?si=IIRwK7cRcrfU0K1E](https://youtu.be/31t7jyiUw3I?si=IIRwK7cRcrfU0K1E)

---

[https://youtu.be/50bJGmlF54Q?si=KXy3Aq4l-5f_SBgm](https://youtu.be/50bJGmlF54Q?si=KXy3Aq4l-5f_SBgm)

[https://drive.google.com/drive/folders/1eQhV7VjYvbUjdPRBkt-Feh6n9A50mIaH?usp=drive_link](https://drive.google.com/drive/folders/1eQhV7VjYvbUjdPRBkt-Feh6n9A50mIaH?usp=drive_link)